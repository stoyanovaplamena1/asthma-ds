{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e719f0c8-12f0-4e47-b497-77e8c315bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4f5775-3f5a-40f8-9e96-c0894c3ad97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "OUT_DIR = DATA_DIR\n",
    "\n",
    "df = pd.read_parquet(DATA_DIR / \"asthma_clean.parquet\",  engine=\"fastparquet\")  # from Problem 3/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d9a90-b35b-4ecf-a81d-3ed7ca7d0090",
   "metadata": {},
   "source": [
    "#### Define feature groups\n",
    "\n",
    "The first step in feature manipulation is to make explicit and reproducible groups of features. This matters because:\n",
    "\n",
    "- It keeps preprocessing consistent across notebooks and scripts.\n",
    "\n",
    "- It makes feature engineering easier later (e.g., scaling continuous variables only, or encoding categorical variables).\n",
    "\n",
    "In this dataset, I structured features into clear groups:\n",
    "\n",
    "- Demographics: age, gender, ethnicity, education_level\n",
    "\n",
    "- Lifestyle factors: bmi, smoking, physical_activity, diet_quality, sleep_quality\n",
    "\n",
    "- Environmental exposures: pollution_exposure, pollen_exposure, dust_exposure\n",
    "\n",
    "- Medical history: pet_allergy, family_history_asthma, history_of_allergies, eczema, hay_fever, gastroesophageal_reflux\n",
    "\n",
    "- Lung function: lung_function_fev1, lung_function_fvc, fev1_fvc_pct\n",
    "\n",
    "- Symptoms: wheezing, shortness_of_breath, chest_tightness, coughing, nighttime_symptoms, exercise_induced\n",
    "\n",
    "- Target: diagnosis\n",
    "\n",
    "This grouping is not just bookkeeping — it helps us test hypotheses. For example:\n",
    "\n",
    "Are lifestyle factors predictive independently of medical history?\n",
    "\n",
    "Are lung function measures redundant with symptom reports?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0397349-8557-4bec-ad5e-bd0ea2407165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2392, 28) | y positive rate: 0.0518\n"
     ]
    }
   ],
   "source": [
    "target = \"diagnosis\"\n",
    "\n",
    "# Identify columns by pattern\n",
    "symptoms = [\n",
    "    \"wheezing\",\"shortness_of_breath\",\"chest_tightness\",\n",
    "    \"coughing\",\"nighttime_symptoms\",\"exercise_induced\"\n",
    "]\n",
    "atopy = [\"eczema\",\"hay_fever\",\"history_of_allergies\",\"pet_allergy\"]\n",
    "exposures = [\"pollution_exposure\",\"pollen_exposure\",\"dust_exposure\"]\n",
    "lifestyle = [\"physical_activity\",\"diet_quality\",\"sleep_quality\"]\n",
    "\n",
    "# Ethnicity dummies\n",
    "ethnicity_cols = [c for c in df.columns if c.startswith(\"ethnicity_\")]\n",
    "\n",
    "# Core numerics I keep \n",
    "core_numeric = [\n",
    "    \"age\",\"bmi\",\"lung_function_fev1\",\"fev1_fvc_pct\",\n",
    "    *lifestyle, *exposures\n",
    "]\n",
    "\n",
    "binary_other = [\n",
    "    \"gender\",\"smoking\",\"family_history_asthma\",\"gastroesophageal_reflux\",\n",
    "    *atopy, *symptoms\n",
    "]\n",
    "\n",
    "all_inputs = core_numeric + binary_other + ethnicity_cols\n",
    "X = df[all_inputs].copy()\n",
    "y = df[target].astype(int).copy()\n",
    "\n",
    "print(\"X shape:\", X.shape, \"| y positive rate:\", y.mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf45663-4c1c-4fea-b9ba-5acffe99302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered columns added: ['symptom_count', 'atopy_score', 'lifestyle_index', 'exposure_index', 'ratio_x_symptoms', 'bmi_c', 'bmi_c2']\n"
     ]
    }
   ],
   "source": [
    "# Symptom burden (0–6)\n",
    "X[\"symptom_count\"] = df[symptoms].sum(axis=1).astype(float)\n",
    "\n",
    "# Atopy score (0–4): allergic phenotype burden\n",
    "X[\"atopy_score\"] = df[atopy].sum(axis=1).astype(float)\n",
    "\n",
    "# Lifestyle index (0–10): average of three 0–10 scores\n",
    "X[\"lifestyle_index\"] = df[lifestyle].mean(axis=1)\n",
    "\n",
    "# Exposure index (0–10): average of three 0–10 exposure scores\n",
    "X[\"exposure_index\"] = df[exposures].mean(axis=1)\n",
    "\n",
    "# Simple interaction hypothesis: airflow + symptoms\n",
    "X[\"ratio_x_symptoms\"] = df[\"fev1_fvc_pct\"] * X[\"symptom_count\"]\n",
    "\n",
    "# Optional: nonlinearity hint for BMI (centered quadratic)\n",
    "X[\"bmi_c\"] = df[\"bmi\"] - df[\"bmi\"].mean()\n",
    "X[\"bmi_c2\"] = X[\"bmi_c\"] ** 2\n",
    "\n",
    "print(\"Engineered columns added:\",\n",
    "      [\"symptom_count\",\"atopy_score\",\"lifestyle_index\",\"exposure_index\",\"ratio_x_symptoms\",\"bmi_c\",\"bmi_c2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84d3600-7e5f-420b-b0ad-2a96faa22be2",
   "metadata": {},
   "source": [
    "Why these?\n",
    "\n",
    "symptom_count: overall symptom burden often tracks diagnosis/severity.\n",
    "\n",
    "atopy_score: captures allergic phenotype breadth.\n",
    "\n",
    "lifestyle/exposure indices: reduce dimensionality of related 0–10 scales.\n",
    "\n",
    "ratio_x_symptoms: hypothesis that obstruction signal is stronger when symptoms co-occur.\n",
    "\n",
    "bmi_c2: cheap nonlinearity; obesity/asthma links aren’t always linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b07d8a-2e7e-4653-a1fb-4d3080543ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaNs in X? False\n",
      "dtypes: {dtype('float64'): 35}\n"
     ]
    }
   ],
   "source": [
    "# Cast booleans/ints to float; keep dummies as 0/1 floats (models-friendly)\n",
    "X_numeric = X.copy()\n",
    "for c in X_numeric.columns:\n",
    "    if X_numeric[c].dtype == \"boolean\":\n",
    "        X_numeric[c] = X_numeric[c].astype(float)\n",
    "    elif str(X_numeric[c].dtype).startswith(\"int\") or X_numeric[c].dtype == bool:\n",
    "        X_numeric[c] = X_numeric[c].astype(float)\n",
    "\n",
    "# Sanity checks\n",
    "print(\"Any NaNs in X?\", X_numeric.isna().any().any())\n",
    "print(\"dtypes:\", X_numeric.dtypes.value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b789e90e-a5fe-4544-8b19-d9fa04664d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-variance dropped: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lifestyle_index</td>\n",
       "      <td>0.012516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>history_of_allergies</td>\n",
       "      <td>0.010180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>symptom_count</td>\n",
       "      <td>0.007339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>family_history_asthma</td>\n",
       "      <td>0.006643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ethnicity_african_american</td>\n",
       "      <td>0.006058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pet_allergy</td>\n",
       "      <td>0.005472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bmi_c</td>\n",
       "      <td>0.005352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bmi</td>\n",
       "      <td>0.005352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pollen_exposure</td>\n",
       "      <td>0.005240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shortness_of_breath</td>\n",
       "      <td>0.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>atopy_score</td>\n",
       "      <td>0.003843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nighttime_symptoms</td>\n",
       "      <td>0.003628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.003434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>eczema</td>\n",
       "      <td>0.003243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gastroesophageal_reflux</td>\n",
       "      <td>0.002720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature        mi\n",
       "30             lifestyle_index  0.012516\n",
       "16        history_of_allergies  0.010180\n",
       "28               symptom_count  0.007339\n",
       "12       family_history_asthma  0.006643\n",
       "24  ethnicity_african_american  0.006058\n",
       "17                 pet_allergy  0.005472\n",
       "33                       bmi_c  0.005352\n",
       "1                          bmi  0.005352\n",
       "8              pollen_exposure  0.005240\n",
       "19         shortness_of_breath  0.004015\n",
       "29                 atopy_score  0.003843\n",
       "22          nighttime_symptoms  0.003628\n",
       "10                      gender  0.003434\n",
       "14                      eczema  0.003243\n",
       "13     gastroesophageal_reflux  0.002720"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove near-zero variance columns first (e.g., constants)\n",
    "vt = VarianceThreshold(threshold=1e-8)\n",
    "_ = vt.fit(X_numeric)\n",
    "low_var_cols = [col for col, keep in zip(X_numeric.columns, vt.get_support()) if not keep]\n",
    "print(\"Low-variance dropped:\", low_var_cols)\n",
    "X_screen = X_numeric.drop(columns=low_var_cols)\n",
    "\n",
    "# Mutual information (nonlinear-friendly univariate signal)\n",
    "mi = mutual_info_classif(X_screen, y, discrete_features=False, random_state=42)\n",
    "mi_rank = (pd.DataFrame({\"feature\": X_screen.columns, \"mi\": mi})\n",
    "           .sort_values(\"mi\", ascending=False))\n",
    "mi_rank.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce1147-20e9-4167-9a3d-42afdf8991ee",
   "metadata": {},
   "source": [
    "I screened features using variance and mutual information. All features carried at least some variance, and none had zero univariate signal. Because asthma is multifactorial, I kept all features for now and will rely on modeling to down-weight weak predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138af699-cb96-4e69-b9ad-85df13eaf44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X shape: (2392, 35)\n",
      "Scaled columns (first 8): ['bmi_c2', 'diet_quality', 'dust_exposure', 'pollen_exposure', 'ratio_x_symptoms', 'atopy_score', 'physical_activity', 'lifestyle_index']\n",
      "Means (should be ~0):\n",
      " bmi_c2              0.0\n",
      "diet_quality       -0.0\n",
      "dust_exposure       0.0\n",
      "pollen_exposure     0.0\n",
      "ratio_x_symptoms    0.0\n",
      "dtype: float64\n",
      "Stds  (should be ~1):\n",
      " bmi_c2              1.0\n",
      "diet_quality        1.0\n",
      "dust_exposure       1.0\n",
      "pollen_exposure     1.0\n",
      "ratio_x_symptoms    1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Identify columns to scale (intersection with what's in X_screen)\n",
    "scale_cols = list(set(core_numeric + [\n",
    "    \"symptom_count\",\"atopy_score\",\"lifestyle_index\",\n",
    "    \"exposure_index\",\"ratio_x_symptoms\",\"bmi_c\",\"bmi_c2\"\n",
    "]) & set(X_screen.columns))\n",
    "\n",
    "# Pass-through = everything not scaled\n",
    "passthrough_cols = [c for c in X_screen.columns if c not in scale_cols]\n",
    "\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"scale\", StandardScaler(with_mean=True, with_std=True), scale_cols),\n",
    "        (\"keep\", \"passthrough\", passthrough_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Fit/transform to get the final numeric matrix\n",
    "X_final = preproc.fit_transform(X_screen)\n",
    "final_cols = list(preproc.get_feature_names_out())\n",
    "X_final = pd.DataFrame(X_final, columns=final_cols)\n",
    "\n",
    "print(\"Final X shape:\", X_final.shape)\n",
    "print(\"Scaled columns (first 8):\", scale_cols[:8])\n",
    "\n",
    "# Quick sanity check: standardized columns should have ~0 mean and ~1 std\n",
    "means = X_final[scale_cols].mean().round(3)\n",
    "stds  = X_final[scale_cols].std(ddof=0).round(3)\n",
    "print(\"Means (should be ~0):\\n\", means.head())\n",
    "print(\"Stds  (should be ~1):\\n\", stds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9303b50-7ad4-4e95-81ca-17365ab21acc",
   "metadata": {},
   "source": [
    "I standardized continuous features (mean = 0, std = 1) while keeping binary/dummies as-is. This avoids scale dominance in models like logistic regression, SVMs, or regularized classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781d3481-66a0-4727-abf2-9dd833e19503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1913, 35) Test: (479, 35) | y+ rate: 0.0518 0.0522\n"
     ]
    }
   ],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_final, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Train:\", X_tr.shape, \"Test:\", X_te.shape, \"| y+ rate:\", y_tr.mean().round(4), y_te.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9920459-fd93-4dee-8acb-42b77c355678",
   "metadata": {},
   "source": [
    "I used a stratified 80/20 split, ensuring the asthma positive rate (~5%) is preserved across both sets. This prevents sampling bias and gives a reliable basis for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd70de0-ba7f-4f63-85b3-812e39d38784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - C:\\Data Science\\07.Data-Science-Project-Architecture-Lab\\data\\processed\\asthma_features.parquet \n",
      " - C:\\Data Science\\07.Data-Science-Project-Architecture-Lab\\data\\processed\\asthma_target.parquet\n"
     ]
    }
   ],
   "source": [
    "X_final.to_parquet(OUT_DIR / \"asthma_features.parquet\", index=False)\n",
    "y.to_frame(\"diagnosis\").to_parquet(OUT_DIR / \"asthma_target.parquet\", index=False)\n",
    "print(\"Saved:\\n -\", OUT_DIR / \"asthma_features.parquet\", \"\\n -\", OUT_DIR / \"asthma_target.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ffcc3-8006-4583-ae89-1c0fc3ef1429",
   "metadata": {},
   "source": [
    "I saved:\n",
    "\n",
    "X_final.parquet → Features (numeric, standardized, engineered).\n",
    "\n",
    "y.parquet → Target.\n",
    "\n",
    "This avoids re-running preprocessing every time and ensures reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9faf316-fe74-417c-8502-b26522f6b677",
   "metadata": {},
   "source": [
    "In this step, I transformed the cleaned dataset into a model-ready feature table. Features were grouped by clinical meaning, and several engineered variables (symptom burden, atopy score, lifestyle and exposure indices, BMI quadratic term, etc.) were added to capture plausible asthma-related mechanisms. All features were converted to numeric, screened for variance and univariate signal, and continuous variables were standardized to ensure comparability across scales.\n",
    "\n",
    "Rather than discarding weak features at this stage, I kept them all, since asthma diagnosis is a multifactorial condition and interactions may reveal additional signal. Finally, I split the dataset into stratified train/test sets and saved the processed tables in a reproducible format.\n",
    "\n",
    "The result is a rectangular, all-numeric dataset (35 features, 2392 patients) that is ready for downstream modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a712c-7c47-402d-b022-bab86f6ad9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
